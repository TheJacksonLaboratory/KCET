{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest predictions\n",
    "This notebook ingests the positive and negative training vectors as well as positive and negative validation sets as generated by the notebook ``ExtractDifferenceVectorsHistoricalLaterYear.ipynb``.Positive and training datasets are obtained up to the taregt year. Positive and negative validation sets are obtained for a specific year which is at least one year after the target year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from kcet import KcetParser\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "fig.tight_layout()\n",
    "\n",
    "target_year = 2012\n",
    "\n",
    "for num_years_later in range(1,2):\n",
    "    positive_validation_pickle_path = \"positive-valid-vectors-{}-years-after-{}.pkl\".format(num_years_later,target_year)\n",
    "    negative_validation_pickle_path = \"negative-valid-vectors-{}-years-after-{}.pkl\".format(num_years_later, target_year)\n",
    "    positive_train_pickle_path = \"positive-train-vectors-{}.pkl\".format(target_year)\n",
    "    negative_train_pickle_path =  \"negative-train-vectors-{}.pkl\".format(target_year)\n",
    "    diff_vectors_pos_validation = pd.read_pickle(positive_validation_pickle_path)\n",
    "    diff_vectors_neg_validation = pd.read_pickle(negative_validation_pickle_path)\n",
    "    diff_vectors_pos_training = pd.read_pickle(positive_train_pickle_path)\n",
    "    diff_vectors_neg_training = pd.read_pickle(negative_train_pickle_path)\n",
    "    print(\"number of positive training links upto {}: {}\".format(target_year,diff_vectors_pos_training.shape[0]))\n",
    "    print(\"number of negative training links upto {}: {}\".format(target_year,diff_vectors_neg_training.shape[0]))\n",
    "    print(\"number of positive validation links {} years after {} : {}\".format(num_years_later, target_year, diff_vectors_pos_validation.shape[0]))\n",
    "    print(\"number of negative validation links {} years after {} : {}\".format(num_years_later, target_year, diff_vectors_neg_training.shape[0]))\n",
    "    \n",
    "    X_train = pd.concat([diff_vectors_pos_training,diff_vectors_neg_training])\n",
    "    print(\"Total training vectors: %d\" % len(X_train))\n",
    "    \n",
    "    label_1 = np.ones(diff_vectors_pos_training.shape[0])\n",
    "    label_0 = np.zeros(diff_vectors_neg_training.shape[0])\n",
    "    y_train = np.concatenate((label_1,label_0))\n",
    "    print(\"Total training labels: %d\" % len(y_train))\n",
    "    \n",
    "    X_test = pd.concat([diff_vectors_pos_validation,diff_vectors_neg_validation])\n",
    "    print(\"Total test vectors: %d\" % len(X_test))\n",
    "    \n",
    "    label_1 = np.ones(diff_vectors_pos_validation.shape[0])\n",
    "    label_0 = np.zeros(diff_vectors_neg_validation.shape[0])\n",
    "    y_test = np.concatenate((label_1,label_0))\n",
    "    print(\"Total test labels: %d\" % len(y_test))\n",
    "    \n",
    "    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    #Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 3, 5, 7, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    print(random_grid)\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 1, cv = 10, verbose=2, random_state=42)\n",
    "\n",
    "    rf_random.fit(X_train,y_train)\n",
    "\n",
    "    best_model = rf_random.best_estimator_\n",
    "    \n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    yproba = best_model.predict_proba(X_test)[::,1]\n",
    "    \n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(metrics.confusion_matrix(y_test,y_pred))\n",
    "    precision, recall, _ = precision_recall_curve(y_test, yproba) \n",
    "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "    auc_roc = roc_auc_score(y_test, yproba)\n",
    "    auc_recall_precision = auc(recall, precision)\n",
    "    ax1.plot(fpr, tpr, label='%d year(s) after %d, ROC (area = %0.2f)' % (num_years_later, target_year, auc_roc))\n",
    "    ax2.plot(recall, precision, label='%d year(s) after %d, precision-recall (area = %0.2f)' % (num_years_later,target_year, auc_recall_precision))\n",
    "    ax1.set_title('Receiver Operating Characteristic Curve from pubmed abstracts up to 2010')\n",
    "    ax1.set_xlabel('1-Specificity(False Positive Rate)')\n",
    "    ax1.set_ylabel('Sensitivity(True Positive Rate)')\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax2.set_title('Precision-Recall Curve from pubmed abstracts up to 2010')\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcet_env",
   "language": "python",
   "name": "kcet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

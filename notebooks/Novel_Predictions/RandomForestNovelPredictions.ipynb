{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest predictions\n",
    "This notebook ingests the positive and negative training vectors as well as the prediction set as generated by the notebook ``ExtractDifferenceVectors.ipynb``. It then perfoms Random forest learning and ranks the prediction set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from kcet import KcetParser\n",
    "import pickle5 as pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_pickle_path = \"predictions.pkl\"\n",
    "positive_diff_pickle_path =  \"positive-vectors.pkl\"\n",
    "negative_diff_pickle_path =  \"negative-vectors.pkl\"\n",
    "with open(prediction_pickle_path, \"rb\") as fpred:\n",
    "     diff_vectors_prediction = pickle.load(fpred)\n",
    "with open(positive_diff_pickle_path, \"rb\") as fpos:        \n",
    "    diff_vectors_pos = pickle.load(fpos)\n",
    "with open(negative_diff_pickle_path, \"rb\") as fneg:    \n",
    "    diff_vectors_neg = pickle.load(fneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_vectors_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_vectors_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_vectors_neg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest\n",
    "### 1. Training set\n",
    "Create the training set by concatenating ``diff_vectors_pos`` and ``diff_vectors_neg``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([diff_vectors_pos,diff_vectors_neg])\n",
    "print(\"Total training vectors: %d\" % len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = np.ones(diff_vectors_pos.shape[0])\n",
    "label_0 = np.zeros(diff_vectors_neg.shape[0])\n",
    "y_train = np.concatenate((label_1,label_0))\n",
    "print(\"Total training labels: %d\" % len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test set. \n",
    "The test set is the prediction set with one label (either 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = diff_vectors_prediction\n",
    "label_test = np.ones(diff_vectors_prediction.shape[0])\n",
    "y_test = label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 7, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search over the parameters to choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 10, verbose=2, random_state=42)\n",
    "\n",
    "rf_random.fit(X_train,y_train)\n",
    "\n",
    "best_model = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "yproba = best_model.predict_proba(X_test)[::,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding results\n",
    "The ``KcetParser`` class has methods that take the raw X_test vectors and create an annotated dataframe by\n",
    "decoding strings like ``ncbigene5599-meshd000074723`` to show the corresponding gene symbols and MeSH labels (neoplasms),\n",
    "and also placing the probabilities of the predictions in the corresponding rows. The resulting dataframe\n",
    "is sorted according to probability. The ``deleteEmbeddings`` argument determines whether we only return the\n",
    "three columns ``gene_symbol1``, ``cancer``, and ``probability``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kcet import KcetParser\n",
    "kcetParser = KcetParser()\n",
    "predictions = kcetParser.decode_predictions(vectors=X_test, probabilities=yproba, deleteEmbeddings=True)\n",
    "predictions.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of predictions:\", len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"predictions_novel.tsv\",index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distributions of positive and negative examples\n",
    "Here, we plot the distributions of the probabiliies of the positive and negative examples as calculated by the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenated the vectors as follows. ``X_train = pd.concat([diff_vectors_pos,diff_vectors_neg])``\n",
    "Therefore, we can extract the individual predictions as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_probs = []\n",
    "neg_probs = []\n",
    "n_pos = len(diff_vectors_pos)\n",
    "n_predictions = len(predictions)\n",
    "print(\"[INFO] Extracting %d positive predictions from a total of %d\" % (n_pos, n_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_predictions):\n",
    "    row = predictions.iloc[i]\n",
    "    pr = float(row['probability'])\n",
    "    if i < n_pos:\n",
    "        pos_probs.append(pr)\n",
    "    else:\n",
    "        neg_probs.append(pr)\n",
    "# sanity check\n",
    "print(\"[INFO] Got %d positive and %d negative predictions\" % (len(pos_probs), len(neg_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posnp = np.array(pos_probs)\n",
    "negnp = np.array(neg_probs)\n",
    "p1=sns.kdeplot(data=posnp, shade=True, color=\"r\")\n",
    "p1=sns.kdeplot(data=negnp, shade=True, color=\"b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive examples are shown in red and the negative examples in blue. The separation is of course\n",
    "an expected result. \n",
    "We can calculate some values to estimate some threshold probabilities for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum prob, positive group:\", np.min(posnp))\n",
    "print(\"Maximum prob, positive group:\", np.max(posnp))\n",
    "print(\"prob at 1st percentile, positive group:\", np.percentile(posnp, 1))\n",
    "print(\"prob at 5th percentile, positive group:\", np.percentile(posnp, 5))\n",
    "print(\"prob at 10th percentile, positive group:\", np.percentile(posnp, 20))\n",
    "print(\"prob at 20th percentile, positive group:\", np.percentile(posnp, 20))\n",
    "print()\n",
    "print(\"Minimum prob, negative group:\", np.min(negnp))\n",
    "print(\"Maximum prob, negative group:\", np.max(negnp))\n",
    "print(\"prob at 99th percentile, negative group:\", np.percentile(negnp, 99))\n",
    "print(\"prob at 95th percentile, negative group:\", np.percentile(negnp, 95))\n",
    "print(\"prob at 90th percentile, negative group:\", np.percentile(negnp, 90))\n",
    "print(\"prob at 80th percentile, negative group:\", np.percentile(negnp, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabiity distribution of prediction scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probility = []\n",
    "for i in range(n_predictions):\n",
    "    row = predictions.iloc[i]\n",
    "    pr = float(row['probability'])\n",
    "    probility.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(probility)\n",
    "import pandas as pd\n",
    "x = pd.Series(scores, name=\"Prediction score\")\n",
    "#p=sns.kdeplot(data=scores, x=\"d\", shade=True, color=\"b\")\n",
    "ax = sns.kdeplot(x,shade=True,color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcet_env",
   "language": "python",
   "name": "kcet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

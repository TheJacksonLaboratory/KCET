{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest predictions\n",
    "This notebook ingests the positive and negative training vectors as well as positive and negative validation sets as generated by the notebook ``ExtractDifferenceVectorsHistoricalLaterYear.ipynb``.Positive and training datasets are obtained up to the taregt year. Positive and negative validation sets are obtained for a specific year which is at least one year after the target year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from kcet import KcetParser\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax1 = fig.add_subplot(111)\n",
    "#ax2 = fig.add_subplot(122)\n",
    "fig.tight_layout()\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "target_year = 2010\n",
    "mid_year= 2011 \n",
    "\n",
    "for num_years_later in [0,1,2,3,4,5,6,7,8,9]:\n",
    "    positive_validation_pickle_path = \"positive-valid-vectors-{}-years-after-{}-target-{}.pkl\".format(num_years_later,mid_year,target_year)\n",
    "    negative_validation_pickle_path = \"negative-valid-vectors-{}.pkl\".format(target_year)\n",
    "    positive_train_pickle_path = \"positive-train-vectors-{}.pkl\".format(target_year)\n",
    "    negative_train_pickle_path =  \"negative-train-vectors-{}.pkl\".format(target_year)\n",
    "    diff_vectors_pos_validation = pd.read_pickle(positive_validation_pickle_path)\n",
    "    diff_vectors_neg_validation = pd.read_pickle(negative_validation_pickle_path)\n",
    "    diff_vectors_pos_training = pd.read_pickle(positive_train_pickle_path)\n",
    "    diff_vectors_neg_training = pd.read_pickle(negative_train_pickle_path)\n",
    "    print(\"number of positive training links upto {}: {}\".format(target_year,diff_vectors_pos_training.shape[0]))\n",
    "    print(\"number of negative training links upto {}: {}\".format(target_year,diff_vectors_neg_training.shape[0]))\n",
    "    print(\"number of positive validation links {} years after {} : {}\".format(num_years_later, mid_year, diff_vectors_pos_validation.shape[0]))\n",
    "    print(\"number of negative validation links {} years after {} : {}\".format(num_years_later, mid_year, diff_vectors_neg_training.shape[0]))\n",
    "    \n",
    "    X_train = pd.concat([diff_vectors_pos_training,diff_vectors_neg_training])\n",
    "    print(\"Total training vectors: %d\" % len(X_train))\n",
    "    \n",
    "    label_1 = np.ones(diff_vectors_pos_training.shape[0])\n",
    "    label_0 = np.zeros(diff_vectors_neg_training.shape[0])\n",
    "    y_train = np.concatenate((label_1,label_0))\n",
    "    print(\"Total training labels: %d\" % len(y_train))\n",
    "    \n",
    "    X_test = pd.concat([diff_vectors_pos_validation,diff_vectors_neg_validation])\n",
    "    print(\"Total test vectors: %d\" % len(X_test))\n",
    "    \n",
    "    label_1 = np.ones(diff_vectors_pos_validation.shape[0])\n",
    "    label_0 = np.zeros(diff_vectors_neg_validation.shape[0])\n",
    "    y_test = np.concatenate((label_1,label_0))\n",
    "    print(\"Total test labels: %d\" % len(y_test))\n",
    "    \n",
    "    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    #Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 3, 5, 7, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    print(random_grid)\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 1, cv = 10, random_state=42)\n",
    "\n",
    "    rf_random.fit(X_train,y_train)\n",
    "\n",
    "    best_model = rf_random.best_estimator_\n",
    "    \n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    yproba = best_model.predict_proba(X_test)[::,1]\n",
    "    \n",
    "    fpr, tpr, thresholds_auc = roc_curve(y_test,  yproba)\n",
    "    #gmeans = sqrt(tpr * (1-fpr))\n",
    "    # locate the index of the largest g-mean\n",
    "    #ix_gmeans = argmax(gmeans)\n",
    "   # print('Best Threshold=%.5f, G-Mean=%.3f' % (thresholds_auc[ix_gmeans], gmeans[ix_gmeans]))\n",
    "    \n",
    "    \n",
    "    print(metrics.confusion_matrix(y_test,y_pred))\n",
    "    auc_roc = roc_auc_score(y_test, yproba)\n",
    "    \n",
    "    \n",
    "    ax1.plot(fpr, tpr, label='%d-%d (%0.2f), n=%d' %(mid_year, mid_year + num_years_later  ,auc_roc, diff_vectors_pos_validation.shape[0]))\n",
    "    #ax1.scatter(fpr[ix_gmeans], tpr[ix_gmeans], marker='o', color='black')\n",
    "    \n",
    "        \n",
    "        \n",
    "    precision, recall, thresholds_pr = precision_recall_curve(y_test, yproba)\n",
    "    # convert to f score\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    #print(\"precision\", precision, 'recall', recall)\n",
    "    diff_threshold = 0.01\n",
    "    for i in range(len(fscore)):\n",
    "        if abs(recall[i] - 0.5 * precision[i]) < diff_threshold:\n",
    "            print(precision[i],recall[i])\n",
    "            break\n",
    "    # locate the index of the largest f score\n",
    "    #ix_fscore = argmax(fscore)\n",
    "    ix_fscore = i\n",
    "    print(' Threshold=%.5f, F-Score=%.2f' % (thresholds_pr[ix_fscore], fscore[ix_fscore]))\n",
    "    precision_at_threshold = precision_score(y_test, y_pred > thresholds_pr[ix_fscore])\n",
    "    recall_at_threshold = recall_score(y_test, y_pred > thresholds_pr[ix_fscore])\n",
    "    print('precision=%.2f, recall=%.2f\\n\\n' % (precision_at_threshold, recall_at_threshold))\n",
    "    \n",
    "    #ax2.plot(recall, precision, label='%d year(s) after %d, precision-recall (area = %0.2f)' % (num_years_later,target_year, auc_recall_precision))\n",
    "    ax1.set_title('Target year = {}'.format(target_year))\n",
    "    ax1.set_xlabel('1-Specificity')\n",
    "    ax1.set_ylabel('Sensitivity')\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcet_env",
   "language": "python",
   "name": "kcet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
